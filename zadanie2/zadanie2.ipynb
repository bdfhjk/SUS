{
 "metadata": {
  "name": "",
  "signature": "sha256:3099759cc350971c266996071c2b2f06d9d164e55e710cf5b40c9b05d53a4415"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import csv\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from itertools import product\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn import linear_model, grid_search, tree\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "le = preprocessing.LabelEncoder()\n",
      "\n",
      "reload(sys)\n",
      "sys.setdefaultencoding(\"utf-8\")\n",
      "%matplotlib inline\n",
      "\n",
      "df  = pd.read_csv('dane_treningowe.csv')\n",
      "final_df = pd.read_csv('dane_testowe.csv')\n",
      "df['rezultat'] = df['rezultat'].map(lambda x: 1 if x == 'yes' else 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Analiza danych\n",
      "--------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_normalized = df\n",
      "\n",
      "parameters_to_num = ['zawod', 'stan_cywilny', 'wyksztalcenie', 'debet', 'hipoteka', 'pozyczka', 'poprzedni_wynik']\n",
      "\n",
      "for p in parameters_to_num:\n",
      "    df_normalized[p] = le.fit_transform(df_normalized[p])\n",
      "\n",
      "df2 = df_normalized.corr()\n",
      "df2['rezultat'].sort_values()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "wskaznik_zatrudnienia    -0.357718\n",
        "przerwa                  -0.335194\n",
        "EURIBOR3M                -0.310161\n",
        "zmiennosc_zatrudnienia   -0.297650\n",
        "CPI                      -0.130314\n",
        "debet                    -0.101487\n",
        "liczba_kontaktow         -0.067018\n",
        "pozyczka                 -0.002850\n",
        "id_klienta                0.010672\n",
        "hipoteka                  0.014809\n",
        "zawod                     0.026190\n",
        "wiek                      0.030422\n",
        "stan_cywilny              0.044316\n",
        "CCI                       0.049454\n",
        "wyksztalcenie             0.058622\n",
        "poprzedni_wynik           0.135674\n",
        "poprzednie                0.238842\n",
        "rezultat                  1.000000\n",
        "Name: rezultat, dtype: float64"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u0141atwo zauwa\u017cy\u0107, \u017ce szczeg\u00f3lnie istotne parametry kt\u00f3re w liniowy spos\u00f3b wp\u0142ywaj\u0105 na wynik to odpowiednio\n",
      "* wska\u017anik_zatrudnienia (35%)\n",
      "* przerwa (33%)\n",
      "* EURIBOR3m (31%)\n",
      "* zmiennosc_zatrudnienia (29%)\n",
      "* poprzednie (23%)\n",
      "* poprzednie_wynik (13%)\n",
      "* debet (10%)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Algorytm\n",
      "---------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "np.random.randn(42)\n",
      "msk = np.random.rand(len(df)) < 0.8\n",
      "\n",
      "train_df = df[msk]\n",
      "test_df  = df[~msk]\n",
      "\n",
      "def preprocess(_df):\n",
      "    \n",
      "    parameters = ['wskaznik_zatrudnienia', 'przerwa', 'poprzednie', 'zmiennosc_zatrudnienia', 'EURIBOR3M', 'poprzedni_wynik', 'debet']\n",
      "    X = _df[parameters]\n",
      "    X['poprzedni_wynik'] = le.fit_transform(X['poprzedni_wynik'])\n",
      "    \n",
      "    \n",
      "    if 'rezultat' in _df:\n",
      "        Y = _df['rezultat']\n",
      "    else:\n",
      "        Y = X\n",
      "    return (X,Y)\n",
      "\n",
      "(train_X, train_Y) = preprocess(train_df)\n",
      "(test_X, test_Y)   = preprocess(test_df)\n",
      "(final_X, _)       = preprocess(final_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sprawdzam, czy istnieje korelacja mi\u0119dzy klas\u0105 decyzyjn\u0105 a pozosta\u0142ymi kolumnami zbioru danych"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "df2 = train_X.corr()\n",
      "\n",
      "vals = np.around(df2.values,2)\n",
      "normal = plt.normalize(-1, 1)\n",
      "\n",
      "fig = plt.figure(figsize=(15,8))\n",
      "ax = fig.add_subplot(111, frameon=True, xticks=[], yticks=[])\n",
      "\n",
      "the_table=plt.table(cellText=vals, rowLabels=df2.index, colLabels=df2.columns, \n",
      "                    colWidths = [0.06]*vals.shape[1], loc='center', \n",
      "                    cellColours=plt.cm.hot(normal(vals)))\n",
      "the_table.set_fontsize(14)\n",
      "the_table.scale(3, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Na podstawie powy\u017cszej tabelki mo\u017cna stwierdzi\u0107, i\u017c\u00a0istnieje statystycznie istotna korelacja mi\u0119dzy warto\u015bciami w kolumnach C* a warto\u015bci\u0105 klasy decyzyjnej\n",
      "\n",
      "Nast\u0119pnie sprawdzam korelacje mi\u0119dzy kolumnami C*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = df.corr()\n",
      "\n",
      "vals = np.around(df2.values,2)\n",
      "normal = plt.normalize(-0.1, 0.1)\n",
      "\n",
      "fig = plt.figure(figsize=(15,8))\n",
      "ax = fig.add_subplot(111, frameon=True, xticks=[], yticks=[])\n",
      "\n",
      "the_table=plt.table(cellText=vals, rowLabels=df2.index, colLabels=df2.columns, \n",
      "                    colWidths = [0.06]*vals.shape[1], loc='center', \n",
      "                    cellColours=plt.cm.hot(normal(vals)))\n",
      "the_table.set_fontsize(12)\n",
      "the_table.scale(1.5, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tym razem mo\u017cemy stwierdzi\u0107 brak statystycznie istotnej korelacji mi\u0119dzy kolumnami. Wobec tego, u\u017cycie klasyfikatora dzia\u0142aj\u0105cego liniowo wzgl\u0119dem danych powinno by\u0107 wystarczaj\u0105ce.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nast\u0119pnie sprawdzam liczno\u015b\u0107 klasy decyzyjnych z \"1\" oraz \"0\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(df[df['rezultat'] == 1].count()['rezultat']) / df.count()['rezultat']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.11317857142857143"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Poniewa\u017c\u00a0rozk\u0142ad \"1\" oraz \"0\" w klasie decyzyjnej jest r\u00f3wnomierny, nie jest konieczne u\u017cycie F-Score do wyznacznia dok\u0142adno\u015bci klasyfikatora, wystarczy policzy\u0107\u00a0precyzj\u0119 na zbiorze testowym"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------------------------------------------------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Poni\u017cej przedstawiam przebieg i wyniki bada\u0144. GridSearchCV jest funkcj\u0105, kt\u00f3ra automatycznie dopasowuje najlepsze parametry z podanych list na podstawie wyniku na walidacji krzy\u017cowej.\n",
      "\n",
      "Jako\u015b\u0107 ostatecznego wyniku dla ka\u017cdego z algorytm\u00f3w zbada\u0142em na zbiorze testowym."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = pd.DataFrame()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knc = KNeighborsClassifier()\n",
      "parameters = {'weights':('uniform', 'distance'), 'algorithm':('auto', 'ball_tree', 'kd_tree', 'brute')}\n",
      "\n",
      "clf = grid_search.GridSearchCV(knc, parameters, n_jobs=-1, scoring='f1')\n",
      "clf.fit(train_X, train_Y)\n",
      "clf.score(test_X, test_Y)\n",
      "#results = results.append({'Klasyfikator':'kNN', 'Wynik':score, 'Parametry':str(clf.best_params_)}, ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dtc = tree.DecisionTreeClassifier()\n",
      "\n",
      "parameters = {\n",
      "    'max_depth': (50, 100, 150),\n",
      "    'min_samples_split': (1, 2, 3),\n",
      "    'min_samples_leaf': (1, 2, 3)\n",
      "}\n",
      "\n",
      "clf = grid_search.GridSearchCV(dtc, parameters, n_jobs=-1, scoring='f1')\n",
      "clf.fit(train_X, train_Y)\n",
      "score = clf.score(test_X, test_Y)\n",
      "#results = results.append({'Klasyfikator':'Drzewo decyzyjne', \n",
      "#                          'Wynik':score, 'Parametry':str(clf.best_params_)}, ignore_index=True)\n",
      "score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.35079726651480636"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = linear_model.LogisticRegression()\n",
      "parameters = {'penalty':('l1', 'l2'), 'C':[0.00001, 0.00005, 0.0001, 0.0005, 0.001]}\n",
      "\n",
      "clf = grid_search.GridSearchCV(lr, parameters, n_jobs=-1, scoring='f1')\n",
      "clf.fit(train_X, train_Y)\n",
      "clf.score(test_X, test_Y)\n",
      "#results = results.append({'Klasyfikator':'Regresja logistyczna', \n",
      "#                          'Wynik':score, 'Parametry':str(clf.best_params_)}, ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.32281553398058249"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlp = MLPClassifier(max_iter=1000, hidden_layer_sizes=(10, 10))\n",
      "\n",
      "parameters = {\n",
      "    'algorithm':('l-bfgs', 'sgd'),\n",
      "    'alpha':(1e-2, 1e-3, 1e-4),\n",
      "    'learning_rate':('invscaling', 'adaptive'),\n",
      "\n",
      "}\n",
      "clf = grid_search.GridSearchCV(mlp, parameters, n_jobs=-1, scoring='f1')\n",
      "clf.fit(train_X, train_Y)\n",
      "clf.score(test_X, test_Y)\n",
      "\n",
      "#results = results.append({'Klasyfikator':'Sie\u0107 neuronowa (10)', \n",
      "#                          'Wynik':score, 'Parametry':str(clf.best_params_)}, ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Podsumowanie\n",
      "------------\n",
      "\n",
      "Jak wynika z poni\u017cszej tabelki, najlepszy wynik spo\u015br\u00f3d sprawdzonych algorytm\u00f3w mo\u017cna uzyska\u0107 stosuj\u0105c sie\u0107 neuronow\u0105 o 10 warstwach ukrytych i jest to 89.7%. Z poznanych do tej pory algorymt\u00f3w najlepiej sprawdzi\u0142\u00a0si\u0119 algorytm Naive Bayes z dok\u0142adno\u015bci\u0105 klasyfikacji 86.4%."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.set_option('max_colwidth', 800)\n",
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "knc = KNeighborsClassifier(weights='uniform', algorithm='brute')\n",
      "knc.fit(train_X, train_Y)\n",
      "test_P = knc.predict(test_X)\n",
      "f1_score(test_Y, test_P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dtc = RandomForestClassifier()\n",
      "parameters = {\n",
      "    'max_depth':range(5,200,5),\n",
      "    'min_samples_leaf':range(5,15,5),\n",
      "    'min_samples_split':range(5,15,5)\n",
      "}\n",
      "clf = grid_search.GridSearchCV(dtc, parameters, n_jobs=-1, scoring='f1')\n",
      "\n",
      "#dtc = tree.DecisionTreeClassifier(max_depth=20, min_samples_leaf=15, min_samples_split=12)\n",
      "clf.fit(train_X, train_Y)\n",
      "test_P = clf.predict(test_X)\n",
      "f1_score(test_Y, test_P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_final = pd.read_csv('dane_testowe.csv')\n",
      "final_X = df_final[['przerwa', 'poprzednie', 'zmiennosc_zatrudnienia', 'wskaznik_zatrudnienia', 'EURIBOR3M']]\n",
      "arr = knc.predict(final_X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "answer = pd.DataFrame()\n",
      "ids = df_final['id_klienta']\n",
      "for i in range(0, len(ids)):\n",
      "    if arr[i] == 1 or (1000-len(answer)) >= (len(ids) - i) :\n",
      "        answer = answer.append({'id':str(ids[i]), 'value':arr[i]}, ignore_index=True)\n",
      "    \n",
      "answer.to_csv('answer.csv', sep='\\t')    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "answer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}