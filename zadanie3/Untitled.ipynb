{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import pandas as pd\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from skimage import segmentation\n",
    "from skimage.morphology import watershed\n",
    "from skimage import morphology\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "df = pd.DataFrame(columns=('name', 'x', 'y', 'bpc', 'blobs', 'lines', 's1', 's2', 's3', 's4'))\n",
    "\n",
    "'''\n",
    "compare_list = []\n",
    "compare_list.append(('input/4503.png', 6)) #U\n",
    "compare_list.append(('input/39.png' , 1)) #r\n",
    "compare_list.append(('input/201.png', 2)) #i\n",
    "compare_list.append(('input/823.png', 3)) #t\n",
    "compare_list.append(('input/201.png', 4)) #i\n",
    "compare_list.append(('input/3860.png', 5)) #M\n",
    "compare_list.append(('input/4503.png', 6)) #U\n",
    "compare_list.append(('input/2150.png', 7)) #C\n",
    "compare_list.append(('input/1154.png', 7)) #Å»\n",
    "compare_list.append(('input/6076.png', 8)) #E\n",
    "compare_list.append(('input/5002.png', 9)) #R\n",
    "'''\n",
    "\n",
    "def get_max_hough_similarity(image1, image2):\n",
    "    image1 = cv2.GaussianBlur(image1,(3,3),0)\n",
    "    image2 = cv2.GaussianBlur(image2,(3,3),0)\n",
    "    sim    = 0\n",
    "    simsum = 0\n",
    "    maxs = 0\n",
    "    x1, y1, _ = image1.shape\n",
    "    x2, y2, _ = image2.shape\n",
    "    dx = 0\n",
    "    dy = 0 \n",
    "    for dx in range(-3,4):\n",
    "        for dy in range(-3, 4):\n",
    "            sim = 0\n",
    "            simsum = 0\n",
    "            for i in range(0, min(x1,x2)):\n",
    "                for j in range(0, min(y1,y2)):\n",
    "                    if i+dx >= 0 and i+dx < x2 and j+dy >= 0 and j+dy < y2:\n",
    "                        if image1[i][j][0] == image2[i+dx][j+dy][0]:\n",
    "                            sim = sim + 1\n",
    "                        simsum = simsum + 1    \n",
    "            #print 'sim %d simsum %d' % (sim, simsum)\n",
    "            if simsum != 0:\n",
    "                maxs = max(maxs, (1.0*sim/simsum) * 100)\n",
    "    #print 'dx=%d dy=%d %d - %d = %d p' % (dx, dy, sim, simsum, (1.0*sim/simsum * 100))\n",
    "    return maxs\n",
    "\n",
    "def iterate_hough(image1):\n",
    "    ans = 0\n",
    "    for path, val in compare_list:\n",
    "        #print path\n",
    "        image2 = io.imread(path)\n",
    "        value = get_max_hough_similarity(image1, image2)\n",
    "        if (value > 85):\n",
    "            ans += val * 100000000\n",
    "    return ans\n",
    "\n",
    "def get_intensity(image):\n",
    "    bpc = 0\n",
    "    low_bc = 0\n",
    "    high_bc = 0\n",
    "    left_bc = 0\n",
    "    right_bc = 0\n",
    " \n",
    "    mx, my, _ = image.shape\n",
    "\n",
    "    for iy in range(my):\n",
    "        for ix in range(mx):\n",
    "            if image[ix][iy][0] == 0:\n",
    "                bpc = bpc + 1\n",
    "                if iy < (my/2):\n",
    "                    left_bc = left_bc + 1\n",
    "                if iy >= (my/2):\n",
    "                    right_bc = right_bc + 1\n",
    "                if ix < (mx/2):\n",
    "                    low_bc = low_bc + 1\n",
    "                if ix >= (mx/2):\n",
    "                    high_bc = high_bc + 1\n",
    "    return (bpc, low_bc, high_bc, left_bc, right_bc)\n",
    "\n",
    "def get_lines(img):\n",
    "    img = ndimage.minimum_filter(img, size=2)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,10)\n",
    "    if lines is None:\n",
    "        num_lin = 0\n",
    "    else:\n",
    "        num_lin = len(lines[0])\n",
    "    \n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,10)\n",
    "    if lines is None:\n",
    "        num_lin = 0\n",
    "    else:\n",
    "        num_lin = len(lines[0])\n",
    "    return num_lin\n",
    "\n",
    "def get_blobs(image):\n",
    "    im = ndimage.minimum_filter(image, size=2)\n",
    "    blobs, number_of_blobs = ndimage.label(im)\n",
    "    return number_of_blobs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100 / 6168\n",
      "Progress 200 / 6168\n",
      "Progress 300 / 6168\n",
      "Progress 400 / 6168\n",
      "Progress 500 / 6168\n",
      "Progress 600 / 6168\n",
      "Progress 700 / 6168\n",
      "Progress 800 / 6168\n",
      "Progress 900 / 6168\n",
      "Progress 1000 / 6168\n",
      "Progress 1100 / 6168\n",
      "Progress 1200 / 6168\n",
      "Progress 1300 / 6168\n",
      "Progress 1400 / 6168\n",
      "Progress 1500 / 6168\n",
      "Progress 1600 / 6168\n",
      "Progress 1700 / 6168\n",
      "Progress 1800 / 6168\n",
      "Progress 1900 / 6168\n",
      "Progress 2000 / 6168\n",
      "Progress 2100 / 6168\n",
      "Progress 2200 / 6168\n",
      "Progress 2300 / 6168\n",
      "Progress 2400 / 6168\n",
      "Progress 2500 / 6168\n",
      "Progress 2600 / 6168\n",
      "Progress 2700 / 6168\n",
      "Progress 2800 / 6168\n",
      "Progress 2900 / 6168\n",
      "Progress 3000 / 6168\n",
      "Progress 3100 / 6168\n",
      "Progress 3200 / 6168\n",
      "Progress 3300 / 6168\n",
      "Progress 3400 / 6168\n",
      "Progress 3500 / 6168\n",
      "Progress 3600 / 6168\n",
      "Progress 3700 / 6168\n",
      "Progress 3800 / 6168\n",
      "Progress 3900 / 6168\n",
      "Progress 4000 / 6168\n",
      "Progress 4100 / 6168\n",
      "Progress 4200 / 6168\n",
      "Progress 4300 / 6168\n",
      "Progress 4400 / 6168\n",
      "Progress 4500 / 6168\n",
      "Progress 4600 / 6168\n",
      "Progress 4700 / 6168\n",
      "Progress 4800 / 6168\n",
      "Progress 4900 / 6168\n",
      "Progress 5000 / 6168\n",
      "Progress 5100 / 6168\n",
      "Progress 5200 / 6168\n",
      "Progress 5300 / 6168\n",
      "Progress 5400 / 6168\n",
      "Progress 5500 / 6168\n",
      "Progress 5600 / 6168\n",
      "Progress 5700 / 6168\n",
      "Progress 5800 / 6168\n",
      "Progress 5900 / 6168\n",
      "Progress 6000 / 6168\n",
      "Progress 6100 / 6168\n",
      "Calculated\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6169):\n",
    "    image_path = 'input/%d.png' % i\n",
    "    image_name = '%d.png' % i\n",
    "    image = io.imread(image_path)    \n",
    "    img   = cv2.imread(image_path)\n",
    "    x,y,_ = image.shape    \n",
    "    \n",
    "    bpc, lwbpc, hbpc, ltbpc, rbpc = get_intensity(image)\n",
    "    num_lin = get_lines(img)\n",
    "    number_of_blobs = get_blobs(image)\n",
    "    #simil = iterate_hough(image)\n",
    "\n",
    "    df.loc[i] = [image_name, int(x),int(y),int(bpc), 1000 * int(number_of_blobs), 5 * int(num_lin),\n",
    "                 int(lwbpc), int (hbpc), int(ltbpc), int(rbpc)]\n",
    "    if (i%100 == 0):\n",
    "        print 'Progress %d / 6168' % i\n",
    "print 'Calculated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted to df, starting aggregation...\n"
     ]
    }
   ],
   "source": [
    "def convert(x):\n",
    "    try:\n",
    "        return x.astype(int)\n",
    "    except:\n",
    "        return x\n",
    "df = df.apply(convert)\n",
    "print 'converted to df, starting aggregation...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agregated, starting saving\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cl = AgglomerativeClustering(n_clusters=59)\n",
    "df2 = cl.fit_predict(df.drop('name', axis=1))\n",
    "print 'Agregated, starting saving'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = pd.Series(df2, index=range(1,len(df2)+1))\n",
    "df3 = pd.concat([df, s], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/500.png category/3/500.png\n",
      "input/1000.png category/4/1000.png\n",
      "input/1500.png category/5/1500.png\n",
      "input/2000.png category/14/2000.png\n",
      "input/2500.png category/9/2500.png\n",
      "input/3000.png category/4/3000.png\n",
      "input/3500.png category/4/3500.png\n",
      "input/4000.png category/1/4000.png\n",
      "input/4500.png category/5/4500.png\n",
      "input/5000.png category/14/5000.png\n",
      "input/5500.png category/6/5500.png\n",
      "input/6000.png category/2/6000.png\n",
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "path = \"category\"\n",
    "os.mkdir(path)\n",
    "for i in range(0,60):\n",
    "    path = \"category/%d\" % i\n",
    "    os.mkdir(path, 0755 );\n",
    "\n",
    "for r in range(1,6169):\n",
    "    image_name = df3.loc[r][0]\n",
    "    image_cat = df3.loc[r][df3.shape[1] - 1]\n",
    "    image_path_in = 'input/%s' % image_name\n",
    "    image_path_out = 'category/%d/%s' % (image_cat, image_name)\n",
    "    copyfile(image_path_in, image_path_out)\n",
    "    if r % 500 == 0:\n",
    "        print image_path_in + \" \" + image_path_out\n",
    "print 'Saved.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare submission\n",
      "Submission saved.\n"
     ]
    }
   ],
   "source": [
    "print 'Prepare submission'\n",
    "df3.to_csv('submission.csv', index=False, header=False)\n",
    "print 'Submission saved.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-8-0d4eb2191bfc>, line 48)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-0d4eb2191bfc>\"\u001b[1;36m, line \u001b[1;32m48\u001b[0m\n\u001b[1;33m    #cv2.imwrite('houghlines3.jpg',img)\u001b[0m\n\u001b[1;37m                                       \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "df3.loc[2912]\n",
    "for i in range(1, 2):\n",
    "    image_path = 'input/%d.png' % i\n",
    "    image_name = '%d.png' % i\n",
    "    image = io.imread(image_path)\n",
    "    distance = ndimage.distance_transform_edt(image)\n",
    "    local_maxi = peak_local_max(image, indices=False)\n",
    "    markers = morphology.label(local_maxi)\n",
    "    labels_ws = watershed(-distance, markers, mask=image)\n",
    "    #markers[~image] = -1\n",
    "    #labels_rw = segmentation.random_walker(image, markers)\n",
    "labels_ws.shape\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#flatten to make greyscale, using your second red-black image as input.\n",
    "#img = scipy.misc.imread('input/903.png',flatten=1)\n",
    "#smooth and threshold as image has compression artifacts (jpg)\n",
    "\n",
    "im[im<10]=0\n",
    "img = cv2.imread('input/87.png')\n",
    "#img = ndimage.minimum_filter(img, size=2)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "lines = cv2.HoughCircles(gray,cv2.cv.CV_HOUGH_GRADIENT,1,300,50,10)\n",
    "if lines is None:\n",
    "    num_lin = -1\n",
    "else:\n",
    "    num_lin = len(lines)\n",
    "\"\"\"\n",
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 100*(-b))\n",
    "    y1 = int(y0 + 100*(a))\n",
    "    x2 = int(x0 - 100*(-b))\n",
    "    y2 = int(y0 - 100*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),1)\"\"\"\n",
    "\n",
    "#plt.imshow(edges)\n",
    "#plt.show()\n",
    "print num_lin\n",
    "#cv2.imwrite('houghlines3.jpg',img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.loc[4503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'AKAZE_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d5d585177e5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mkaze_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input/1154.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input/1632.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-d5d585177e5d>\u001b[0m in \u001b[0;36mkaze_match\u001b[1;34m(im1_path, im2_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# initialize the AKAZE descriptor, then detect keypoints and extract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# local invariant descriptors from the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAKAZE_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mkps1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescs1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mkps2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescs2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'AKAZE_create'"
     ]
    }
   ],
   "source": [
    "def kaze_match(im1_path, im2_path):\n",
    "    # load the image and convert it to grayscale\n",
    "    im1 = cv2.imread(im1_path)\n",
    "    im2 = cv2.imread(im2_path)\n",
    "    gray1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)    \n",
    "\n",
    "    # initialize the AKAZE descriptor, then detect keypoints and extract\n",
    "    # local invariant descriptors from the image\n",
    "    detector = cv2.AKAZE_create()\n",
    "    (kps1, descs1) = detector.detectAndCompute(gray1, None)\n",
    "    (kps2, descs2) = detector.detectAndCompute(gray2, None)\n",
    "\n",
    "    print(\"keypoints: {}, descriptors: {}\".format(len(kps1), descs1.shape))\n",
    "    print(\"keypoints: {}, descriptors: {}\".format(len(kps2), descs2.shape))    \n",
    "\n",
    "    # Match the features\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    matches = bf.knnMatch(descs1,descs1, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.9*n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    # cv2.drawMatchesKnn expects list of lists as matches.\n",
    "    im3 = cv2.drawMatchesKnn(im1, kps1, im2, kps2, good[1:20], None, flags=2)\n",
    "    cv2.imshow(\"AKAZE matching\", im3)\n",
    "    cv2.waitKey(0) \n",
    "\n",
    "kaze_match('input/1154.png', 'input/1632.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
